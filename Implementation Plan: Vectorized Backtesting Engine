# **ðŸ§ª Implementation Plan: Vectorized Backtesting Engine**

## **1\. Executive Summary**

This document provides a concrete roadmap for integrating a robust, vectorized backtesting engine into the **AI Crypto Trading Bot**. By transitioning from simple single-point simulations to matrix-based historical stress testing, we will enable rapid strategy optimization, high-fidelity risk analysis, and future-proof the bot for higher-frequency trading intervals.

## **2\. Phase 1: Data Infrastructure & Bulk Acquisition**

To ensure high-fidelity results, we must support high-resolution (1-minute) data, even if the trading cycle remains at 60 minutes.

### **2.1. Update data\_collector.py**

* **Method:** Add fetch\_bulk\_historical\_data(product\_id, start\_date, end\_date, granularity='ONE\_MINUTE').  
* **Logic:** Implement automated pagination for the Coinbase get\_candles API (limited to 300 candles per request).  
* **Validation:** Add checks for data gaps and auto-fill logic (forward-fill) to ensure a continuous time series.

### **2.2. Storage Layer**

* **Format:** Store bulk data in **Apache Parquet** format within data/historical/. Parquet is optimized for columnar vectorized reads.  
* **Organization:** data/historical/{asset}\_{granularity}\_history.parquet.

## **3\. Phase 2: Strategy Vectorization**

The existing strategies in strategies/ must be adapted to run as vectorized functions using **VectorBT** and **Pandas-TA**.

### **3.1. Indicator Factory**

Create utils/indicator\_factory.py to pre-calculate all technical indicators for the entire historical dataset at once.

* **Vectorization:** Use pandas\_ta for bulk calculation of RSI, MACD, and Bollinger Bands.  
* **Memory Management:** Ensure dataframes are cleared after signal generation to prevent OOM (Out of Memory) issues during long-term tests.

### **3.2. Market Regime Vectorization**

* Map the AdaptiveStrategyManager logic into a boolean mask.  
* Generate a "Regime Vector" (e.g., 0 for Ranging, 1 for Trending, 2 for Volatile) for every timestamp in the historical data.

### **3.3. Multi-Strategy Consensus Matrix**

* Implement a weighted signal matrix where:$$FinalSignal \= (Signal\_A \\times Weight\_A) \+ (Signal\_B \\times Weight\_B) \+ ...$$  
* This allows the backtester to simulate the "Hierarchical Decision Making" currently used in the AdaptiveStrategyManager.

## **4\. Phase 3: Execution & Capital Simulation**

The engine must mirror the real-world constraints of the CoinbaseClient and CapitalManager.

### **4.1. The Backtest Engine (utils/backtest\_engine.py)**

* **Library:** Use vbt.Portfolio.from\_signals() as the primary simulation engine.  
* **Fee Modeling:** Configure a fixed fees=0.006 (0.6%) per trade to reflect Coinbase retail taker fees.  
* **Slippage:** Apply a slippage=0.0005 (0.05%) factor to account for order book depth and latency.

### **4.2. Capital Constraint Integration**

* **Liquidity Buffer:** Replicate MIN\_EUR\_RESERVE (â‚¬50) by restricting the maximum available capital used for vbt entries.  
* **Position Caps:** Enforce MAX\_POSITION\_SIZE\_PERCENT (35%) logic within the vectorized sizing function.

## **5\. Phase 4: Optimization & Dashboard**

Integrate the results into the botâ€™s existing monitoring ecosystem.

### **5.1. Hyperparameter Search**

* Implement a grid search utility to test variations of:  
  * CONFIDENCE\_THRESHOLD\_BUY (40% to 80%)  
  * DECISION\_INTERVAL\_MINUTES (15, 30, 60\)  
* **Objective:** Maximize the **Sortino Ratio** (return vs. downside risk) rather than just raw profit.

### **5.2. Dashboard Integration (performance.html)**

* **New Component:** Add a "Backtest Analysis" tab.  
* **Comparison:** Plot the "Live Equity Curve" vs. the "Backtested Potential" to identify "Alpha Leakage."  
* **Tear Sheet:** Display Sharpe Ratio, Max Drawdown, and Win Rate for the backtested period.

## **6\. Implementation Timeline**

| Week | Focus | Deliverables |
| :---- | :---- | :---- |
| **Week 1** | Data & Dependencies | Bulk downloaders, Parquet storage, vectorbt setup. |
| **Week 2** | Strategy Porting | Vectorized versions of Trend, MeanRev, and Momentum. |
| **Week 3** | Logic Alignment | Consensus matrix and CapitalManager simulation. |
| **Week 4** | Dashboard & Opt. | Backtest UI and Parameter Grid Search. |

## **7\. Risks and Mitigations**

* **Risk:** Look-ahead Bias (the bot "seeing" future data during backtest).  
* **Mitigation:** Ensure all indicators are shifted (.shift(1)) so signals are generated using only data available *before* the trade.  
* **Risk:** Data Overfitting.  
* **Mitigation:** Use **Walk-Forward Analysis**; train on 70% of historical data, test on the remaining 30%.

## **8\. Recommendations & Next Steps**

### **8.1. Isolated Research Directory (README Recommendation)**

It is highly recommended to create a separate README.md within a new /backtest directory. This directory should be treated as the "Research & Development" arm of the project.

* **Purpose:** Distinguish between production bot logic and the local research environment.  
* **Content:** Document how to download bulk data, how to run grid searches, and how to interpret the resulting "Strategy Tear Sheets."  
* **Security:** Ensure data/historical/\*.parquet is added to .gitignore to keep the production repository lightweight.

### **8.2. Local Execution Paradigm**

Backtesting should be performed exclusively in a **local development environment**.

* **Hardware:** Vectorized operations are RAM-intensive; local machines typically have more resources than the t2.medium or e2-medium cloud instances used for production.  
* **Workflow:** Optimize settings locally â†’ Update .env in production â†’ Restart live service.

### **8.3. "Dry-Run" Verification**

Before committing to a new set of optimized parameters, run a 7-day "Dry-Run" in the production environment's current Simulation Mode to verify that the backtest predictions align with live-data behavior.
